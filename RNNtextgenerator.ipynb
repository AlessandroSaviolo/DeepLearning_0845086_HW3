{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlAbIm0TMSrx",
        "colab_type": "text"
      },
      "source": [
        "# RECURSIVE NEURAL NETWORK FOR TEXT PREDICTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qShG6TAMJtW",
        "colab_type": "text"
      },
      "source": [
        "### 1. Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI5lSgLjKsRx",
        "colab_type": "code",
        "outputId": "9a28092a-6957-4cb5-cea3-d34e36b543b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9QXZ6b0DBUn",
        "colab_type": "code",
        "outputId": "f70ae5c4-4421-4588-b5c8-3eaa009110e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cd ~/../content/gdrive/My Drive/Colab Notebooks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYfW7BBQMMOt",
        "colab_type": "text"
      },
      "source": [
        "### 2. Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3zvfP0ZKva5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, SimpleRNN\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "import io\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YdwmjPlMnnH",
        "colab_type": "text"
      },
      "source": [
        "### 3. Define Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMTrkAHbMuT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyper parameters\n",
        "train_path = 'shakespeare_train.txt'\n",
        "val_path = 'shakespeare_valid.txt'\n",
        "sequence_len = 40\n",
        "step = 3\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "num_epochs = 5\n",
        "\n",
        "# flags\n",
        "model_type = 0                      # 0 -> Simple RNN, 1 -> LSTM\n",
        "verbose = 1                         # 0 -> no verbosity, 1 -> verbosity\n",
        "output_text = 0                     # 0 -> text output callback off, 1 -> text output callback on"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Lns54MM3iN",
        "colab_type": "text"
      },
      "source": [
        "### 4. Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN2tGifON3eu",
        "colab_type": "text"
      },
      "source": [
        "4.1 Load Data from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBXs9EMTN3H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_text(path):\n",
        "    with io.open(path, 'r', encoding='utf8') as f:\n",
        "        return f.read()\n",
        "\n",
        "\n",
        "def load_data(train_path, val_path):\n",
        "    train_text = load_text(train_path)                              # load training text\n",
        "    val_text = load_text(val_path)                                  # load validation text\n",
        "    vocab = sorted(list(set(train_text + val_text)))                # create character's collection\n",
        "    return {\n",
        "        'train_text': train_text,\n",
        "        'val_text': val_text,\n",
        "        'vocab': vocab,\n",
        "        'vocab_to_int': dict((c, i) for i, c in enumerate(vocab)),\n",
        "        'int_to_vocab': dict((i, c) for i, c in enumerate(vocab))\n",
        "    }\n",
        "\n",
        "data = load_data(train_path, val_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dzAXZN_N3nd",
        "colab_type": "text"
      },
      "source": [
        "4.2 Pre-Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krSYZF5vM3TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_sentences(text, sequence_len, step):\n",
        "    sentences, next_chars = [], []\n",
        "    for i in range(0, len(text) - sequence_len, step):\n",
        "        sentences.append(text[i: i + sequence_len])\n",
        "        next_chars.append(text[i + sequence_len])\n",
        "    return sentences, next_chars\n",
        "\n",
        "\n",
        "def encode_sequences(sentences, next_chars, data, sequence_len, vocab_len):\n",
        "    num_sequences = len(sentences)\n",
        "    X = np.zeros((num_sequences, sequence_len, vocab_len), dtype=np.bool)\n",
        "    y = np.zeros((num_sequences, vocab_len), dtype=np.bool)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        for t, char in enumerate(sentence):\n",
        "            X[i, t, data['vocab_to_int'][char]] = 1\n",
        "        y[i, data['vocab_to_int'][next_chars[i]]] = 1\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def preprocess_data(data, sequence_len, step):\n",
        "    # cut the text in semi-redundant sequences of fixed length\n",
        "    train_sentences, train_next_chars = create_sentences(data['train_text'], sequence_len, step)\n",
        "    val_sentences, val_next_chars = create_sentences(data['val_text'], sequence_len, step)\n",
        "\n",
        "    # one hot encode sequences\n",
        "    X_train, y_train = encode_sequences(train_sentences, train_next_chars, data, sequence_len, len(data['vocab']))\n",
        "    X_val, y_val = encode_sequences(val_sentences, val_next_chars, data, sequence_len, len(data['vocab']))\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "\n",
        "X_train, y_train, X_val, y_val = preprocess_data(data, sequence_len, step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGrPCa3eMxiu",
        "colab_type": "text"
      },
      "source": [
        "### 5. Build/Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvUh2StVNS0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_LSTM(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(32, recurrent_regularizer=l2(0.01), return_sequences=True, input_shape=input_shape))\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(input_shape[1], activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_RNN(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(32, recurrent_regularizer=l2(0.01), return_sequences=True, input_shape=input_shape))\n",
        "    model.add(SimpleRNN(32, return_sequences=True))\n",
        "    model.add(SimpleRNN(32))\n",
        "    model.add(Dense(input_shape[1], activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "# build model\n",
        "input_shape = (sequence_len, len(data['vocab']))\n",
        "model = build_RNN(input_shape) if not model_type else build_LSTM(input_shape)\n",
        "\n",
        "# load model\n",
        "# model = load_model('model.h5') if not model_type else load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHwjmfHfNDUF",
        "colab_type": "text"
      },
      "source": [
        "### 6. Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "552k0HJvOhgE",
        "colab_type": "text"
      },
      "source": [
        "6.1 Define Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCbiSZBCOLzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(predictions, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    predictions = np.asarray(predictions).astype('float64')\n",
        "    predictions = np.log(predictions) / temperature\n",
        "    return np.argmax(np.random.multinomial(1, (np.exp(predictions) / np.sum(np.exp(predictions))), 1))\n",
        "\n",
        "\n",
        "class PrintCallback(Callback):\n",
        "    def __init__(self, model, model_name, int_to_vocab, vocab_to_int, sequence_len, vocab_len, text):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.model_name = model_name\n",
        "        self.vocab_to_int = vocab_to_int\n",
        "        self.int_to_vocab = int_to_vocab\n",
        "        self.sequence_len = sequence_len\n",
        "        self.vocab_len = vocab_len\n",
        "        self.text = text\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            start_index = randint(0, len(text) - sequence_len - 1)\n",
        "            sentence = text[start_index: start_index + sequence_len]\n",
        "            # sentence = 'juliet'\n",
        "            generated = sentence\n",
        "            file = open('sentence.txt', 'a')\n",
        "            sys.stdout.write(sentence)\n",
        "            print('Generating with seed: \"' + sentence + '\"')\n",
        "            sys.stdout.write(generated)\n",
        "            for i in range(400):\n",
        "                x_pred = np.zeros((1, sequence_len, vocab_len))\n",
        "                for t, char in enumerate(sentence):\n",
        "                    x_pred[0, t, vocab_to_int[char]] = 1.\n",
        "                predictions = model.predict(x_pred, verbose=0)[0]\n",
        "                next_index = sample(predictions, 3)\n",
        "                next_char = int_to_vocab[next_index]\n",
        "                sentence = sentence[1:] + next_char\n",
        "                sys.stdout.write(next_char)\n",
        "                file.write(next_char)\n",
        "                sys.stdout.flush()\n",
        "            print()\n",
        "            file.close()\n",
        "\n",
        "model_name = 'SimpleRNN_model.h5' if not model_type else 'LSTM_model.h5'\n",
        "callbacks = [\n",
        "             ModelCheckpoint(model_name, save_best_only=True, monitor='val_acc', mode='max'),\n",
        "             EarlyStopping(monitor='val_acc', mode='max', patience=5, verbose=1),\n",
        "             ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, min_lr=0.000001, verbose=1)\n",
        "]\n",
        "if output_text:\n",
        "    callbacks.append(PrintCallback(model, model_name, data['int_to_vocab'], data['vocab_to_int'], sequence_len, len(data['vocab']), data['train_text']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkOETJP4OhWI",
        "colab_type": "text"
      },
      "source": [
        "6.2 Run Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V8kt5YFNSrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model(model, X_train, y_train, X_val, y_val, learning_rate, batch_size, num_epochs, callbacks, verbose):\n",
        "    optimizer = RMSprop(learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=verbose,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return history\n",
        "\n",
        "\n",
        "history = fit_model(\n",
        "    model,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    learning_rate,\n",
        "    batch_size,\n",
        "    num_epochs,\n",
        "    callbacks,\n",
        "    verbose\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqnIXa9AEgBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use this cell for saving model and learning curves\n",
        "\n",
        "model.save('model.h5')\n",
        "\n",
        "with open('results/accuracy.txt', 'w+') as f:  \n",
        "    f.write(str(history.history['acc']))\n",
        "\n",
        "with open('results/val_accuracy.txt', 'w+') as f:  \n",
        "    f.write(str(history.history['val_acc']))\n",
        "\n",
        "with open('results/loss.txt', 'w+') as f:  \n",
        "    f.write(str(history.history['loss']))\n",
        "\n",
        "with open('results/val_loss.txt', 'w+') as f:  \n",
        "    f.write(str(history.history['val_loss']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlt6AjpBNDDJ",
        "colab_type": "text"
      },
      "source": [
        "### 7. Plot Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OENzSv6yMwZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# loss curves\n",
        "    plt.plot(history.history['loss'], 'r', linewidth=3.0)\n",
        "    plt.plot(history.history['val_loss'], 'b', linewidth=3.0)\n",
        "    plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
        "    plt.xlabel('Epochs ', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)\n",
        "    plt.title('Loss Curves', fontsize=16)\n",
        "    plt.savefig('loss_plot.png')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# accuracy curves\n",
        "    plt.plot(history.history['acc'], 'r', linewidth=3.0)\n",
        "    plt.plot(history.history['val_acc'], 'b', linewidth=3.0)\n",
        "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
        "    plt.xlabel('Epochs ', fontsize=16)\n",
        "    plt.ylabel('Accuracy', fontsize=16)\n",
        "    plt.title('Accuracy Curves', fontsize=16)\n",
        "    plt.savefig('acc_plot.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "plot_learning_curves(history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}